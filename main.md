# Teun van der Weij {style="color: #2c3e50; border-bottom: 3px solid #3498db; padding-bottom: 10px"}

<div style="margin-bottom: 2rem;">
  <h4 style="color: #666; margin: 0; font-weight: 500">Research Scientist at Apollo Research</h4>
  <h4 style="color: #666; margin: 0; font-weight: 500">Co-founder & Board Member at the European Network for AI Safety</h4>
</div>

## About me {#about-me style="color: #34495e; border-bottom: 2px solid #3498db; padding-bottom: 5px"}

<div style="display: flex; align-items: flex-start; gap: 30px; margin-bottom: 2rem;">
  <div style="flex: 1; max-width: 600px;">
    <p>I am a Research Scientist at Apollo Research in Zurich. I care about making the world a better place effectively, and therefore I work on making AI systems safer.</p>
  </div>
  <div style="flex-shrink: 0;">
    <img src="weij002_cropped.jpg" alt="teun van der weij" width="200" height="200" style="border-radius: 50%;">
  </div>
</div>

## Work experience {#work-experience style="color: #34495e; border-bottom: 2px solid #3498db; padding-bottom: 5px"}

<div style="display: flex; align-items: center;">
  <h3 style="color: #3498db; display: inline-block; border-left: 4px solid #3498db; padding-left: 10px; margin: 0;">Research scientist at Apollo Research</h3>
  <span style="color: #666; margin-left: 10px;">June 2025 – Present | Zurich/London</span>
</div>

<div style="display: flex; align-items: center;">
  <h3 style="color: #3498db; display: inline-block; border-left: 4px solid #3498db; padding-left: 10px; margin: 0;">AI safety researcher</h3>
  <span style="color: #666; margin-left: 10px;">Jan 2025 – May 2025 | Remote</span>
</div>

I am working on research related to sandbagging and AI control. I examine which (if any) control mechanisms can catch sandbagging and also general sabotage attempts.

<div style="display: flex; align-items: center;">
  <h3 style="color: #3498db; display: inline-block; border-left: 4px solid #3498db; padding-left: 10px; margin: 0;">Resident at Mantic</h3>
  <span style="color: #666; margin-left: 10px;">Oct 2024 – Present | London, UK & Remote</span>
</div>

Mantic has the goal of creating an AI superforecaster. I am working as a research scientist at the start up. Mantic was founded by Toby Shevlane and Ben Day.
<a href="https://mntc.ai" style="display: inline-block; background-color: #f8f9fa; padding: 2px 8px; border-radius: 4px; text-decoration: none; color: #3498db; font-size: 0.9em; margin-top: 5px;">mntc.ai ↗</a>


<div style="display: flex; align-items: center;">
  <h3 style="color: #3498db; display: inline-block; border-left: 4px solid #3498db; padding-left: 10px; margin: 0;">Independent Research on AI Sandbagging</h3>
  <span style="color: #666; margin-left: 10px;">Aug 2024 – Oct 2024 | London, UK & Remote</span>
</div>

Continued research on strategic underperformance on evaluations (sandbagging) with a grant from the AI Safety Fund from the Frontier Model Forum. Together with Francis Rhys Ward and Felix Hofstätter, I continued the research started at MATS.

<div style="display: flex; align-items: center;">
  <h3 style="color: #3498db; display: inline-block; border-left: 4px solid #3498db; padding-left: 10px; margin: 0;">Research Scholar at MATS</h3>
  <span style="color: #666; margin-left: 10px;">Jan 2024 – Jul 2024 | Berkeley, CA, US; London, UK & Remote</span>
</div>

MATS is a program to train AI safety researchers. At MATS, I mostly worked on strategic underperformance on evaluations (sandbagging) of general purpose AI with the mentorship of Francis Rhys Ward.
<a href="https://matsprogram.org" style="display: inline-block; background-color: #f8f9fa; padding: 2px 8px; border-radius: 4px; text-decoration: none; color: #3498db; font-size: 0.9em; margin-top: 5px;">matsprogram.org ↗</a>

<div style="display: flex; align-items: center;">
  <h3 style="color: #3498db; display: inline-block; border-left: 4px solid #3498db; padding-left: 10px; margin: 0;">Co-founder and Co-director at ENAIS</h3>
  <span style="color: #666; margin-left: 10px;">Dec 2022 – Present | Remote</span>
</div>

I co-founded the European Network for AI Safety (ENAIS), with a goal to improve coordination and collaboration between AI Safety researchers and policymakers in Europe.
<a href="https://enais.co" style="display: inline-block; background-color: #f8f9fa; padding: 2px 8px; border-radius: 4px; text-decoration: none; color: #3498db; font-size: 0.9em; margin-top: 5px;">enais.co ↗</a>

<div style="display: flex; align-items: center;">
  <h3 style="color: #3498db; display: inline-block; border-left: 4px solid #3498db; padding-left: 10px; margin: 0;">SPAR participant</h3>
  <span style="color: #666; margin-left: 10px;">Feb 2023 – May 2023 | Remote</span>
</div>

Participated in the Supervised Program for Alignment Research organized at UC Berkeley, focusing on evaluating the shutdown problem in language models.


## Research papers {#research-papers style="color: #34495e; border-bottom: 2px solid #3498db; padding-bottom: 5px"}
*For another overview, see my <a href="https://scholar.google.com/citations?hl=en&user=-fMmbSYAAAAJ" style="display: inline-block; background-color: #f8f9fa; padding: 2px 8px; border-radius: 4px; text-decoration: none; color: #3498db; font-size: 0.9em; margin-top: 5px;">Google Scholar ↗</a>. Although quite some citations are missing, so you can also look at <a href="https://www.semanticscholar.org/author/Teun-van-der-Weij/2221010426" style="display: inline-block; background-color: #f8f9fa; padding: 2px 8px; border-radius: 4px; text-decoration: none; color: #3498db; font-size: 0.9em; margin-top: 5px;">Semantic Scholar ↗</a>.*

#### The Elicitation Game: Evaluating Capability Elicitation Techniques (2024)
**Authors:** Hofstätter, F., **van der Weij, T.**, Teoh, J., Bartsch, H., & Ward, F. R.  
**Venue:** Workshop on Socially Responsible Language Modeling Research  
**Link:** [arXiv preprint arXiv:2502.02180](https://arxiv.org/abs/2502.02180)

Interesting empirical work aiming to inform how evaluators can best elicit AI systems with potentially hidden capabilities.

#### Noise Injection Reveals Hidden Capabilities of Sandbagging Language Models (2024)
**Authors:** Tice, C., Kreer, P. A., Helm-Burger, N., Shahani, P. S., Ryzhenkov, F., Haimes, J., Hofstätter, F., **van der Weij, T.**  
**Venue:** Workshop on Socially Responsible Language Modeling Research  
**Link:** [arXiv preprint arXiv:2412.01784](https://arxiv.org/abs/2412.01784)

I supervised this paper. Adding noise is a very interesting idea, and further experiments are being conducted to see if this can be used to robustly and accurately detect sandbagging.

#### AI Sandbagging: Language Models can Strategically Underperform on Evaluations (2024)
**Authors:** **van der Weij, T.**, Hofstätter, F., Jaffe, O., Brown, S. F., & Ward, F. R.  
**Venue:** ICLR 2025  
**Link:** [arXiv preprint arXiv:2406.07358](https://arxiv.org/abs/2406.07358)

I am most proud of this paper, and I think it's my most impactful work so far. It's great to see our work being used in both technical and governance contexts, inspiring groups at prominent AI safety organizations.

#### Extending Activation Steering to Broad Skills and Multiple Behaviours (2024)
**Authors:** **van der Weij, T.**, Poesio, M., & Schoots, N.  
**Link:** [arXiv preprint arXiv:2403.05767](https://arxiv.org/abs/2403.05767)

This paper was very helpful in improving my technical skills, both in conducting experiments and in understanding transformers. The paper contains some interesting ideas, but it's impact is limited.

#### Evaluating Shutdown Avoidance of Language Models in Textual Scenarios (2023)
**Authors:** **van der Weij, T.**, Lermen, S., & Lang, L.  
**Venue:** Safe & Trusted AI, ICLP 2023  
**Link:** [arXiv PDF](https://arxiv.org/pdf/2307.00787)

My first project in AI safety. In some small experiments, we showed that GPT-4 has the capability to reason correctly about avoiding shutdown in certain scenarios, and actually does this in some cases.

#### Runtime Prediction of Filter Unsupervised Feature Selection Methods (2022)
**Authors:** **van der Weij, T.**, Soancatl Aguilar, V., & Solorio-Fernández, S.  
**Venue:** Research in Computing Science, 150(8), 138-150  
**Link:** [Research Publication](https://research.rug.nl/en/publications/runtime-prediction-of-filter-unsupervised-feature-selection-metho)

## Essays {#essays style="color: #34495e; border-bottom: 2px solid #3498db; padding-bottom: 5px"}
I have written some essays, here's a list.

## Education {#education style="color: #34495e; border-bottom: 2px solid #3498db; padding-bottom: 5px"}

<div style="display: flex; align-items: center;">
  <h3 style="color: #3498db; display: inline-block; border-left: 4px solid #3498db; padding-left: 10px; margin: 0;">MSc Student at Utrecht University</h3>
  <span style="color: #666; margin-left: 10px;">Sep 2022 – Nov 2024 | Utrecht, Netherlands</span>
</div>

Coursework includes Advanced Machine Learning, Natural Language Processing, Human-centered Machine Learning, Pattern Recognition & Deep Learning, and Philosophy of AI.

Grade: 8.2/10

<div style="display: flex; align-items: center;">
  <h3 style="color: #3498db; display: inline-block; border-left: 4px solid #3498db; padding-left: 10px; margin: 0;">BSc Student at University College Groningen</h3>
  <span style="color: #666; margin-left: 10px;">2018 – 2021 | Groningen, Netherlands</span>
</div>

Focus on AI, philosophy, and psychology.

Grade: summa cum laude (with highest distinction).

<div style="display: flex; align-items: center;">
  <h3 style="color: #3498db; display: inline-block; border-left: 4px solid #3498db; padding-left: 10px; margin: 0;">High School Student at Het Nieuwe Eemland</h3>
  <span style="color: #666; margin-left: 10px;">2012 – 2018 | Amersfoort, Netherlands</span>

</div>
Grade: cum laude (with distinction).

## Activity highlights {#activity-highlights style="color: #34495e; border-bottom: 2px solid #3498db; padding-bottom: 5px"}

### Moderator of a Q&A
I moderated a Q&A event with (ex-)OpenAI and Alignment Research Center researchers (Jeff Wu, Jacob Hilton, and Daniel Kokotajlo). We had over 1,800 people attending the event on existential risks posed by AI.

### Presentations
I have presented at various events on AI safety and related topics. Topics include AI sandbagging, how to contribute to AI safety without doing technical research, and more. 

If you want me to present at your event, feel free to reach out. I might charge a fee for the presentation based on the event, but I am happy to discuss this.
ure Selection Methods.* Research in Computing Science, 150(8), 138-150.

### Field-building 
My work at ENAIS is the best example of helping to support the field, but I have also helped organize events like the Dutch AI Safety Retreat.


## Outside of work {#outside-of-work style="color: #34495e; border-bottom: 2px solid #3498db; padding-bottom: 5px"}
I enjoy listening to music, so I go to concerts and festivals quite regularly. I listen to many genres, but my current two favorites are reggae and trance.

I like travelling too, so I try to visit new places when I can. Some favorites are the Nordics, Australia, and Zimbabwe.

Nature is nice too, and I mostly enjoying running, hiking, and snowboarding. Most recently I have gotten into splitboarding, which is taking a snowboard, splitting it in two to make them skis, putting skins underneath, and walk up a mountain. Then you can snowboard down again in beautiful places and hopefully great snow! 

## Contact {#contact style="color: #34495e; border-bottom: 2px solid #3498db; padding-bottom: 5px"}

**Email:** mailvan{first name} @ google's email.