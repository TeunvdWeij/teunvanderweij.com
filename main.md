# Teun van der Weij {style="color: #2c3e50; border-bottom: 3px solid #3498db; padding-bottom: 10px"}
<h4 style="color: #666; margin-top: -10px; text-align: center; font-weight: 500">Resident at Mantic</h4>
<h4 style="color: #666; margin-top: -10px; text-align: center; font-weight: 500">Co-founder & Board Member at ENAIS</h4>

## Table of Contents
- [About Me](#about-me)
- [Work Experience](#work-experience)
- [Education](#education)
- [Recent Activity Highlights](#recent-activity-highlights)
- [Research Papers](#research-papers)
- [Contact](#contact)

<div style="overflow: hidden; margin-top: -200px">
<img src="weij002_cropped.jpg" alt="teun van der weij" width="200" height="200" style="float: right; margin-left: 20px; margin-bottom: 10px; border-radius: 50%">
</div>

## About Me {#about-me style="color: #34495e; border-bottom: 2px solid #3498db; padding-bottom: 5px"}

I am an AI safety researcher currently working as a MATS Scholar, focusing on strategic underperformance on evaluations (sandbagging) of general purpose AI. I'm also a co-founder and board member at ENAIS (European Network for AI Safety), working to improve coordination between AI Safety researchers and policymakers in Europe.

## Work Experience {#work-experience style="color: #34495e; border-bottom: 2px solid #3498db; padding-bottom: 5px"}

<div style="display: flex; align-items: center;">
  <h3 style="color: #3498db; display: inline-block; border-left: 4px solid #3498db; padding-left: 10px; margin: 0;">Resident at Mantic</h3>
  <span style="color: #666; margin-left: 10px;">August 2024 – Present | London, UK</span>
</div>

A research scientist role with the goal of creating an AI superforecaster. 
<a href="https://mntc.ai" style="display: inline-block; background-color: #f8f9fa; padding: 2px 8px; border-radius: 4px; text-decoration: none; color: #3498db; font-size: 0.9em; margin-top: 5px;">mntc.ai ↗</a>

<div style="display: flex; align-items: center;">
  <h3 style="color: #3498db; display: inline-block; border-left: 4px solid #3498db; padding-left: 10px; margin: 0;">Research Scholar at MATS</h3>
  <span style="color: #666; margin-left: 10px;">Jan 2024 – Jul 2024 | Berkeley, CA, US, and London, UK</span>
</div>

Working on strategic underperformance on evaluations (sandbagging) of general purpose AI under the mentorship of Francis Rhys Ward.
<a href="https://matsprogram.org" style="display: inline-block; background-color: #f8f9fa; padding: 2px 8px; border-radius: 4px; text-decoration: none; color: #3498db; font-size: 0.9em; margin-top: 5px;">matsprogram.org ↗</a>

<div style="display: flex; align-items: center;">
  <h3 style="color: #3498db; display: inline-block; border-left: 4px solid #3498db; padding-left: 10px; margin: 0;">Co-founder and Co-director at ENAIS</h3>
  <span style="color: #666; margin-left: 10px;">Dec 2022 – Present | Remote</span>
</div>

Leading initiatives to improve coordination and collaboration between AI Safety researchers and policymakers in Europe.
<a href="https://enais.co" style="display: inline-block; background-color: #f8f9fa; padding: 2px 8px; border-radius: 4px; text-decoration: none; color: #3498db; font-size: 0.9em; margin-top: 5px;">enais.co ↗</a>

<div style="display: flex; align-items: center;">
  <h3 style="color: #3498db; display: inline-block; border-left: 4px solid #3498db; padding-left: 10px; margin: 0;">Junior Researcher at UC Berkeley</h3>
  <span style="color: #666; margin-left: 10px;">Feb 2022 – May 2022 | Remote</span>
</div>

Participated in the Supervised Program for Alignment Research, focusing on evaluating the shutdown problem in language models.

## Education {#education style="color: #34495e; border-bottom: 2px solid #3498db; padding-bottom: 5px"}

<div style="display: flex; align-items: center;">
  <h3 style="color: #3498db; display: inline-block; border-left: 4px solid #3498db; padding-left: 10px; margin: 0;">MSc Student at Utrecht University</h3>
  <span style="color: #666; margin-left: 10px;">Sep 2022 – Nov 2024 | Utrecht, Netherlands</span>
</div>

Coursework includes Advanced Machine Learning, Natural Language Processing, Human-centered Machine Learning, Pattern Recognition & Deep Learning, and Philosophy of AI.

Grade: 8.2/10

<div style="display: flex; align-items: center;">
  <h3 style="color: #3498db; display: inline-block; border-left: 4px solid #3498db; padding-left: 10px; margin: 0;">BSc Student at University College Groningen</h3>
  <span style="color: #666; margin-left: 10px;">2018 – 2021 | Groningen, Netherlands</span>
</div>

Focus on AI, philosophy, and psychology.

Grade: summa cum laude (with highest distinction).

<div style="display: flex; align-items: center;">
  <h3 style="color: #3498db; display: inline-block; border-left: 4px solid #3498db; padding-left: 10px; margin: 0;">High School Student at Het Nieuwe Eemland</h3>
  <span style="color: #666; margin-left: 10px;">2012 – 2018 | Amersfoort, Netherlands</span>

</div>
Grade: cum laude (with distinction).

## Recent Activity Highlights {#recent-activity-highlights style="color: #34495e; border-bottom: 2px solid #3498db; padding-bottom: 5px"}

<div style="display: flex; align-items: center;">
  <h3 style="color: #3498db; display: inline-block; border-left: 4px solid #3498db; padding-left: 10px; margin: 0;">Resident at Mantic</h3>
  <span style="color: #666; margin-left: 10px;">October 2024 | London, UK</span>
</div>
- Announced a new role at **Mantic**, an AI-powered forecasting startup. Researching predictive systems for future events, such as pandemics, elections, and AI developments.
- Highlighted a positive response to the paper *AI Sandbagging: Language Models can Strategically Underperform on Evaluations* and shared follow-up research in collaboration with organizations like Anthropic and GovAI.

<div style="display: flex; align-items: center;">
  <h3 style="color: #3498db; display: inline-block; border-left: 4px solid #3498db; padding-left: 10px; margin: 0;">Research Scholar at MATS</h3>
  <span style="color: #666; margin-left: 10px;">June 2024 | Berkeley, CA</span>
</div>
- Released a paper on sandbagging, exploring the risks posed by AI systems that can hide capabilities during evaluations. The work emphasizes the importance of trustworthy AI evaluations.

<div style="display: flex; align-items: center;">
  <h3 style="color: #3498db; display: inline-block; border-left: 4px solid #3498db; padding-left: 10px; margin: 0;">Research Scholar at MATS</h3>
  <span style="color: #666; margin-left: 10px;">March 2024 | Berkeley, CA</span>
</div>
- Shared findings from a study using activation steering to adjust language models' behaviors, addressing issues like myopia and wealth-seeking tendencies. 

<div style="display: flex; align-items: center;">
  <h3 style="color: #3498db; display: inline-block; border-left: 4px solid #3498db; padding-left: 10px; margin: 0;">Research Scholar at MATS</h3>
  <span style="color: #666; margin-left: 10px;">January 2024 | Berkeley, CA</span>
</div>
- Moderated a high-profile Q&A event with OpenAI and Alignment Research Center researchers, attracting over 1,800 attendees to discuss existential risks posed by AI.

## Research Papers {#research-papers style="color: #34495e; border-bottom: 2px solid #3498db; padding-bottom: 5px"}

<a href="https://scholar.google.com/citations?hl=en&user=-fMmbSYAAAAJ" style="display: inline-block; background-color: #f8f9fa; padding: 2px 8px; border-radius: 4px; text-decoration: none; color: #3498db; font-size: 0.9em; margin-top: 5px;">Google Scholar ↗</a>

- **Hofstätter, F., Teoh, J., van der Weij, T., & Ward, F. R.** (2024). *The Elicitation Game: Stress-Testing Capability Elicitation Techniques.* Workshop on Socially Responsible Language Modeling Research.
- **Tice, C., Kreer, P. A., Helm-Burger, N., Shahani, P. S., Ryzhenkov, F., Haimes, J., et al.** (2024). *Noise Injection Reveals Hidden Capabilities of Sandbagging Language Models.* Workshop on Socially Responsible Language Modeling Research.
- **van der Weij, T., Hofstätter, F., Jaffe, O., Brown, S. F., & Ward, F. R.** (2024). *AI Sandbagging: Language Models can Strategically Underperform on Evaluations.* Workshop on Socially Responsible Language Modeling Research. [Cited by 9]
- **van der Weij, T., Poesio, M., & Schoots, N.** (2024). *Extending Activation Steering to Broad Skills and Multiple Behaviours.* [arXiv preprint arXiv:2403.05767](https://arxiv.org/abs/2403.05767).
- **van der Weij, T., Lermen, S., & Lang, L.** (2023). *Evaluating Shutdown Avoidance of Language Models in Textual Scenarios.* Safe & Trusted AI, ICLP 2023. [Cited by 2]
- **van der Weij, T., Soancatl Aguilar, V., & Solorio-Fernández, S.** (2022). *Runtime Prediction of Filter Unsupervised Feature Selection Methods.* Research in Computing Science, 150(8), 138-150.

## Contact {#contact style="color: #34495e; border-bottom: 2px solid #3498db; padding-bottom: 5px"}

**Email:** mailvanteun@gmail.com
