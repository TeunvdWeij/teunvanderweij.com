<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-08RF5E3N61"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-08RF5E3N61');
</script>

# Teun van der Weij {style="color: #2c3e50; border-bottom: 3px solid #3498db; padding-bottom: 10px"}

## 👤 About me {#about-me style="color: #34495e; border-bottom: 2px solid #3498db; padding-bottom: 5px"}

<div style="display: flex; align-items: flex-start; gap: 30px; margin: -15px 0 2rem;">
  <div style="flex: 1; max-width: 600px;">
    <p>I am a Research Scientist at Apollo Research in Zurich. I care about making the world a better place effectively, and therefore I work on making AI systems safer.</p>

    <p>I am also a board member at the European Network for AI Safety which I co-founded. We are supporting AI safety activity throughout Europe.</p>
  </div>
  <div style="flex-shrink: 0;">
    <img src="weij002_cropped.jpg" alt="Portrait photo of Teun van der Weij, Research Scientist at Apollo Research" width="200" height="200" style="border-radius: 50%;" loading="eager">
  </div>
</div>

## 💼 Work experience {#work-experience style="color: #34495e; border-bottom: 2px solid #3498db; padding-bottom: 5px"}

<div style="display: flex; align-items: center;">
  <h3 style="color: #3498db; display: inline-block; border-left: 4px solid #3498db; padding-left: 10px; margin: 0;">Research scientist at Apollo Research</h3>
  <span style="color: #666; margin-left: 10px;">📅 June 2025 – Present | 📍 Zurich / London</span>
</div>

I predominantly work on evaluating AI capabilities and propensities regarding scheming, and also on AI control. I mostly work from Zurich. 
<a href="https://apolloresearch.ai/" style="display: inline-block; background-color: #f8f9fa; padding: 2px 8px; border-radius: 4px; text-decoration: none; color: #3498db; font-size: 0.9em; margin-top: 5px;">apolloresearch.ai ↗</a>

<div style="display: flex; align-items: center;">
  <h3 style="color: #3498db; display: inline-block; border-left: 4px solid #3498db; padding-left: 10px; margin: 0;">AI safety researcher</h3>
  <span style="color: #666; margin-left: 10px;">📅 Jan 2025 – May 2025 | 📍 Remote</span>
</div>

I worked on research related to sandbagging and AI control. I examined which (if any) control mechanisms can catch sandbagging and also general sabotage attempts.

<div style="display: flex; align-items: center;">
  <h3 style="color: #3498db; display: inline-block; border-left: 4px solid #3498db; padding-left: 10px; margin: 0;">Resident at Mantic</h3>
  <span style="color: #666; margin-left: 10px;">📅 Oct 2024 – Present | 📍 London, UK & Remote</span>
</div>

Mantic has the goal of creating an AI superforecaster. I worked as a research scientist / engineer at the startup. Mantic was founded by Toby Shevlane and Ben Day.
<a href="https://mntc.ai" style="display: inline-block; background-color: #f8f9fa; padding: 2px 8px; border-radius: 4px; text-decoration: none; color: #3498db; font-size: 0.9em; margin-top: 5px;">mntc.ai ↗</a>


<div style="display: flex; align-items: center;">
  <h3 style="color: #3498db; display: inline-block; border-left: 4px solid #3498db; padding-left: 10px; margin: 0;">Independent research on AI sandbagging</h3>
  <span style="color: #666; margin-left: 10px;">📅 Aug 2024 – Oct 2024 | 📍 London, UK & Remote</span>
</div>

Continued research on strategic underperformance on evaluations (sandbagging) with a grant from the AI Safety Fund from the Frontier Model Forum. Together with Francis Rhys Ward and Felix Hofstätter, I continued the research started at MATS.

<div style="display: flex; align-items: center;">
  <h3 style="color: #3498db; display: inline-block; border-left: 4px solid #3498db; padding-left: 10px; margin: 0;">Research scholar at MATS</h3>
  <span style="color: #666; margin-left: 10px;">📅 Jan 2024 – Jul 2024 | 📍 Berkeley, CA, US; London, UK & Remote</span>
</div>

MATS is a program to train AI safety researchers. At MATS, I mostly worked on strategic underperformance on evaluations (sandbagging) of general purpose AI with the mentorship of Francis Rhys Ward.
<a href="https://matsprogram.org" style="display: inline-block; background-color: #f8f9fa; padding: 2px 8px; border-radius: 4px; text-decoration: none; color: #3498db; font-size: 0.9em; margin-top: 5px;">matsprogram.org ↗</a>

<div style="display: flex; align-items: center;">
  <h3 style="color: #3498db; display: inline-block; border-left: 4px solid #3498db; padding-left: 10px; margin: 0;">Co-founder and co-director at ENAIS</h3>
  <span style="color: #666; margin-left: 10px;">📅 Dec 2022 – Present | 📍 Remote</span>
</div>

I co-founded the European Network for AI Safety (ENAIS), with a goal to improve coordination and collaboration between AI Safety researchers and policymakers in Europe.
<a href="https://enais.co" style="display: inline-block; background-color: #f8f9fa; padding: 2px 8px; border-radius: 4px; text-decoration: none; color: #3498db; font-size: 0.9em; margin-top: 5px;">enais.co ↗</a>

<div style="display: flex; align-items: center;">
  <h3 style="color: #3498db; display: inline-block; border-left: 4px solid #3498db; padding-left: 10px; margin: 0;">SPAR participant</h3>
  <span style="color: #666; margin-left: 10px;">📅 Feb 2023 – May 2023 | 📍 Remote</span>
</div>

Participated in the Supervised Program for Alignment Research organized at UC Berkeley, focusing on evaluating the shutdown problem in language models.


## 📄 Research papers {#research-papers style="color: #34495e; border-bottom: 2px solid #3498db; padding-bottom: 5px"}
*For another overview, see my <a href="https://scholar.google.com/citations?hl=en&user=-fMmbSYAAAAJ" style="display: inline-block; background-color: #f8f9fa; padding: 2px 8px; border-radius: 4px; text-decoration: none; color: #3498db; font-size: 0.9em; margin-top: 5px;">Google Scholar ↗</a>. Although quite some citations are missing, so you can also look at <a href="https://www.semanticscholar.org/author/Teun-van-der-Weij/2221010426" style="display: inline-block; background-color: #f8f9fa; padding: 2px 8px; border-radius: 4px; text-decoration: none; color: #3498db; font-size: 0.9em; margin-top: 5px;">Semantic Scholar ↗</a>.*

### The Elicitation Game: Evaluating Capability Elicitation Techniques (2024)
<div style="margin-left: 20px; margin-bottom: 15px;">
  <div style="margin-bottom: 8px;">
    <span style="color: #666; font-size: 0.9em;">👥 <strong>Authors:</strong></span> Hofstätter, F., <strong>van der Weij, T.</strong>, Teoh, J., Bartsch, H., & Ward, F. R.
  </div>
  <div style="margin-bottom: 8px;">
    <span style="color: #666; font-size: 0.9em;">🏛️ <strong>Venue:</strong></span> Workshop on Socially Responsible Language Modeling Research
  </div>
  <div style="margin-bottom: 8px;">
    <span style="color: #666; font-size: 0.9em;">🔗 <strong>Link:</strong></span> <a href="https://arxiv.org/abs/2502.02180" style="color: #3498db;">arXiv:2502.02180</a>
  </div>
  <div style="margin-top: 10px; font-style: italic; color: #555;">
    Interesting empirical work aiming to inform how evaluators can best elicit AI systems with potentially hidden capabilities.
  </div>
</div>

### Noise Injection Reveals Hidden Capabilities of Sandbagging Language Models (2024)
<div style="margin-left: 20px; margin-bottom: 15px;">
  <div style="margin-bottom: 8px;">
    <span style="color: #666; font-size: 0.9em;">👥 <strong>Authors:</strong></span> Tice, C., Kreer, P. A., Helm-Burger, N., Shahani, P. S., Ryzhenkov, F., Haimes, J., Hofstätter, F., <strong>van der Weij, T.</strong>
  </div>
  <div style="margin-bottom: 8px;">
    <span style="color: #666; font-size: 0.9em;">🏛️ <strong>Venue:</strong></span> Workshop on Socially Responsible Language Modeling Research
  </div>
  <div style="margin-bottom: 8px;">
    <span style="color: #666; font-size: 0.9em;">🔗 <strong>Link:</strong></span> <a href="https://arxiv.org/abs/2412.01784" style="color: #3498db;">arXiv:2412.01784</a>
  </div>
  <div style="margin-top: 10px; font-style: italic; color: #555;">
    I supervised this paper. Adding noise is a very interesting idea, and further experiments are being conducted to see if this can be used to robustly and accurately detect sandbagging.
  </div>
</div>

### AI Sandbagging: Language Models can Strategically Underperform on Evaluations (2024) ⭐
<div style="margin-left: 20px; margin-bottom: 15px;">
  <div style="margin-bottom: 8px;">
    <span style="color: #666; font-size: 0.9em;">👥 <strong>Authors:</strong></span> <strong>van der Weij, T.</strong>, Hofstätter, F., Jaffe, O., Brown, S. F., & Ward, F. R.
  </div>
  <div style="margin-bottom: 8px;">
    <span style="color: #666; font-size: 0.9em;">🏛️ <strong>Venue:</strong></span> ICLR 2025
  </div>
  <div style="margin-bottom: 8px;">
    <span style="color: #666; font-size: 0.9em;">🔗 <strong>Link:</strong></span> <a href="https://arxiv.org/abs/2406.07358" style="color: #3498db;">arXiv:2406.07358</a>
  </div>
  <div style="margin-top: 10px; font-style: italic; color: #555;">
    I am most proud of this paper, and I think it's my most impactful work so far. It's great to see our work being used in both technical and governance contexts, inspiring groups at prominent AI safety organizations.
  </div>
</div>

### Extending Activation Steering to Broad Skills and Multiple Behaviours (2024)
<div style="margin-left: 20px; margin-bottom: 15px;">
  <div style="margin-bottom: 8px;">
    <span style="color: #666; font-size: 0.9em;">👥 <strong>Authors:</strong></span> <strong>van der Weij, T.</strong>, Poesio, M., & Schoots, N.
  </div>
  <div style="margin-bottom: 8px;">
    <span style="color: #666; font-size: 0.9em;">🔗 <strong>Link:</strong></span> <a href="https://arxiv.org/abs/2403.05767" style="color: #3498db;">arXiv:2403.05767</a>
  </div>
  <div style="margin-top: 10px; font-style: italic; color: #555;">
    This paper was very helpful in improving my technical skills, both in conducting experiments and in understanding transformers. The paper contains some interesting ideas, but its impact is limited.
  </div>
</div>

### Evaluating Shutdown Avoidance of Language Models in Textual Scenarios (2023)
<div style="margin-left: 20px; margin-bottom: 15px;">
  <div style="margin-bottom: 8px;">
    <span style="color: #666; font-size: 0.9em;">👥 <strong>Authors:</strong></span> <strong>van der Weij, T.</strong>, Lermen, S., & Lang, L.
  </div>
  <div style="margin-bottom: 8px;">
    <span style="color: #666; font-size: 0.9em;">🏛️ <strong>Venue:</strong></span> Safe & Trusted AI, ICLP 2023
  </div>
  <div style="margin-bottom: 8px;">
    <span style="color: #666; font-size: 0.9em;">🔗 <strong>Link:</strong></span> <a href="https://arxiv.org/pdf/2307.00787" style="color: #3498db;">arXiv PDF</a>
  </div>
  <div style="margin-top: 10px; font-style: italic; color: #555;">
    My first project in AI safety. In some small experiments, we showed that GPT-4 has the capability to reason correctly about avoiding shutdown in certain scenarios, and actually does this in some cases.
  </div>
</div>

### Runtime Prediction of Filter Unsupervised Feature Selection Methods (2022)
<div style="margin-left: 20px; margin-bottom: 15px;">
  <div style="margin-bottom: 8px;">
    <span style="color: #666; font-size: 0.9em;">👥 <strong>Authors:</strong></span> <strong>van der Weij, T.</strong>, Soancatl Aguilar, V., & Solorio-Fernández, S.
  </div>
  <div style="margin-bottom: 8px;">
    <span style="color: #666; font-size: 0.9em;">🏛️ <strong>Venue:</strong></span> Research in Computing Science, 150(8), 138-150
  </div>
  <div style="margin-bottom: 8px;">
    <span style="color: #666; font-size: 0.9em;">🔗 <strong>Link:</strong></span> <a href="https://research.rug.nl/en/publications/runtime-prediction-of-filter-unsupervised-feature-selection-metho" style="color: #3498db;">Research Publication</a>
  </div>
</div>

## ✍️ Essays {#essays style="color: #34495e; border-bottom: 2px solid #3498db; padding-bottom: 5px"}
I have written some essays, here's a list.

*   **How to mitigate sandbagging**
    I outline when sandbagging is especially problematic based on three factors: fine-tuning access, data quality, and scorability. I also describe various sandbagging mitigations, so it's a good place to get project ideas. <a href="https://www.alignmentforum.org/posts/Qv5PkrJYAaiBuEJjB/how-to-mitigate-sandbagging-1" style="display: inline-block; background-color: #f8f9fa; padding: 2px 8px; border-radius: 4px; text-decoration: none; color: #3498db; font-size: 0.9em; margin-top: 5px;">Read on Alignment Forum ↗</a>

*   **An introduction to AI sandbagging**
    I describe in more detail what AI sandbagging is. I provide more examples, and take more time to define things. A good place to understand what AI sandbagging is! <a href="https://www.alignmentforum.org/posts/jsmNCj9QKcfdg8fJk/an-introduction-to-ai-sandbagging" style="display: inline-block; background-color: #f8f9fa; padding: 2px 8px; border-radius: 4px; text-decoration: none; color: #3498db; font-size: 0.9em; margin-top: 5px;">Read on Alignment Forum ↗</a>

*   **Simple distribution approximation**
    What happens if you independently sample a language model 100 times with the task of 80% of those outputs being A, and the remaining 20% of outputs being B? Can it do this? <a href="https://www.alignmentforum.org/posts/iaHk9DMCbrYsKuqgS/simple-distribution-approximation-when-sampled-100-times-can-1" style="display: inline-block; background-color: #f8f9fa; padding: 2px 8px; border-radius: 4px; text-decoration: none; color: #3498db; font-size: 0.9em; margin-top: 5px;">Read on Alignment Forum ↗</a>

*   **Beyond humans: why all sentient beings matter in existential risk**
    I not only do empirical machine learning, I like philosophy too! I noticed that definitions about existential risk typically only include humans. I think this should be extended to include all sentient beings (of course humans are very important too). <a href="https://forum.effectivealtruism.org/posts/rXm5xGEGyvfBPAMF9/beyond-humans-why-all-sentient-beings-matter-in-existential-1" style="display: inline-block; background-color: #f8f9fa; padding: 2px 8px; border-radius: 4px; text-decoration: none; color: #3498db; font-size: 0.9em; margin-top: 5px;">Read on EA Forum ↗</a>


## 🎓 Education {#education style="color: #34495e; border-bottom: 2px solid #3498db; padding-bottom: 5px"}

<div style="display: flex; align-items: center;">
  <h3 style="color: #3498db; display: inline-block; border-left: 4px solid #3498db; padding-left: 10px; margin: 0;">MSc at Utrecht University</h3>
  <span style="color: #666; margin-left: 10px;">📅 Sep 2022 – Nov 2024 | 📍 Utrecht, Netherlands</span>
</div>

Coursework includes Advanced Machine Learning, Natural Language Processing, Human-centered Machine Learning, Pattern Recognition & Deep Learning, and Philosophy of AI.

📊 Grade: 8.2/10

<div style="display: flex; align-items: center;">
  <h3 style="color: #3498db; display: inline-block; border-left: 4px solid #3498db; padding-left: 10px; margin: 0;">BSc at University College Groningen</h3>
  <span style="color: #666; margin-left: 10px;">📅 2018 – 2021 | 📍 Groningen, Netherlands</span>
</div>

Focus on AI, philosophy, and psychology.

📊 Grade: summa cum laude (with highest distinction).

<div style="display: flex; align-items: center;">
  <h3 style="color: #3498db; display: inline-block; border-left: 4px solid #3498db; padding-left: 10px; margin: 0;">High school diploma from Het Nieuwe Eemland</h3>
  <span style="color: #666; margin-left: 10px;">📅 2012 – 2018 | 📍 Amersfoort, Netherlands</span>

</div>
📊 Grade: cum laude (with distinction).

## 🔸 Activity highlights {#activity-highlights style="color: #34495e; border-bottom: 2px solid #3498db; padding-bottom: 5px"}

### Moderator of a Q&A
I moderated a Q&A event with (ex-)OpenAI and Alignment Research Center researchers (Jeff Wu, Jacob Hilton, and Daniel Kokotajlo). We had over 1,800 people attending the event on existential risks posed by AI.

### Presentations
I have presented at various events on AI safety and related topics. Topics include AI sandbagging, how to contribute to AI safety without doing technical research, and more. 

If you want me to present at your event, feel free to reach out. I might charge a fee for the presentation based on the event, but I am happy to discuss this.

### Field-building 
My work at ENAIS is the best example of helping to support the field, but I have also helped organize events like the Dutch AI Safety Retreat.


## 🌐 Outside of work {#outside-of-work style="color: #34495e; border-bottom: 2px solid #3498db; padding-bottom: 5px"}
I enjoy listening to music, so I go to concerts and festivals quite regularly. I listen to many genres, but my current two favorites are reggae and trance.

I like travelling too, so I try to visit new places when I can. Some favorites are the Nordics, Australia, and Zimbabwe.

Nature is nice too, and I mostly enjoy running, hiking, and snowboarding. Most recently I have gotten into splitboarding, which is taking a snowboard, splitting it in two to make them skis, putting skins underneath, and walking up a mountain. Then you can snowboard down again in beautiful places and hopefully great snow! 

## 📧 Contact {#contact style="color: #34495e; border-bottom: 2px solid #3498db; padding-bottom: 5px"}

**📧 Email:** mailvan{first name}@{google's email}