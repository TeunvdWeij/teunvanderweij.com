# Teun van der Weij

MATS Scholar | Co-founder & Board Member ENAIS | AI Safety Researcher

![Teun van der Weij](weij002_cropped.jpg)

## About Me

I am an AI safety researcher currently working as a MATS Scholar, focusing on strategic underperformance on evaluations (sandbagging) of general purpose AI. I'm also the co-founder and co-director of ENAIS (European Network for AI Safety), working to improve coordination between AI Safety researchers and policymakers in Europe.

## Work Experience

### Research Scholar at MATS

**Jan 2024 – Present | Berkeley, CA, United States**

Working on strategic underperformance on evaluations (sandbagging) of general purpose AI under the mentorship of Francis Rhys Ward.

### Co-founder and Co-director at ENAIS

**Dec 2022 – Present | Remote**

Leading initiatives to improve coordination and collaboration between AI Safety researchers and policymakers in Europe.

### Junior Researcher at UC Berkeley

**Feb 2022 – May 2022 | Remote**

Participated in the Supervised Program for Alignment Research, focusing on evaluating the shutdown problem in language models.

## Education

### MSc in Artificial Intelligence

**Utrecht University | Sep 2022 – Present**

Coursework includes Advanced Machine Learning, Natural Language Processing, Human-centered Machine Learning, Pattern Recognition & Deep Learning, and Philosophy of AI.

### BSc in Liberal Arts and Sciences

**University College Groningen | 2018 – 2021**

Focus on AI, philosophy, and psychology. Graduated summa cum laude (with highest distinction).

## Recent Activity Highlights

### October 2024
- Announced a new role at **Mantic**, an AI-powered forecasting startup. Researching predictive systems for future events, such as pandemics, elections, and AI developments.
- Highlighted a positive response to the paper *AI Sandbagging: Language Models can Strategically Underperform on Evaluations* and shared follow-up research in collaboration with organizations like Anthropic and GovAI.

### June 2024
- Released a paper on sandbagging, exploring the risks posed by AI systems that can hide capabilities during evaluations. The work emphasizes the importance of trustworthy AI evaluations.

### March 2024
- Shared findings from a study using activation steering to adjust language models' behaviors, addressing issues like myopia and wealth-seeking tendencies. 

### January 2024
- Moderated a high-profile Q&A event with OpenAI and Alignment Research Center researchers, attracting over 1,800 attendees to discuss existential risks posed by AI.

## Research Papers

- **van der Weij, T., Hofstätter, F., Jaffe, O., Brown, S. F., & Ward, F. R.** (2024). *AI Sandbagging: Language Models can Strategically Underperform on Evaluations.* arXiv preprint arXiv:2406.07358.
- **van der Weij, T., Poesio, M., & Schoots, N.** (2024). *Extending Activation Steering to Broad Skills and Multiple Behaviours.* arXiv preprint arXiv:2403.05767.
- **van der Weij, T., & Lermen, S.** (2023). *Evaluating Shutdown Avoidance of Language Models in Textual Scenarios.* arXiv preprint arXiv:2307.00787.
- **van der Weij, T., Soancatl Aguilar, V., & Solorio-Fernández, S.** (2022). *Runtime Prediction of Filter Unsupervised Feature Selection Methods.* Research in Computing Science, 150(8), 138-150.

## Technical Skills

### Programming

- Python
- NumPy
- SciPy
- Scikit-learn
- TensorFlow
- PyTorch

### AI/ML

- Language Models
- APIs
- Machine Learning
- Deep Learning

### Computing

- High-performance computing
- Linux
- GPU/TPU optimization

## Contact

**Email:** mailvanteun@gmail.com  
**Location:** 50% in London, United Kingdom and 50% elsewhere.
