
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Teun van der Weij - AI Safety Researcher</title>
    <style>
        body {
            font-family: 'Arial', sans-serif;
            line-height: 1.6;
            margin: 0;
            padding: 0;
            background-color: #f4f4f4;
            color: #333;
        }

        .container {
            max-width: 900px;
            margin: 0 auto;
            padding: 2rem;
        }

        h1 {
            color: #2c3e50;
            text-align: center;
            padding: 2rem;
            background-color: #fff;
            margin-top: 0;
            box-shadow: 0 2px 5px rgba(0,0,0,0.1);
        }

        h2 {
            color: #2c3e50;
            border-bottom: 2px solid #2c3e50;
            padding-bottom: 0.5rem;
            margin-top: 2rem;
        }

        h3 {
            color: #34495e;
        }

        a {
            color: #3498db;
            text-decoration: none;
        }

        a:hover {
            text-decoration: underline;
        }

        p {
            margin-bottom: 1rem;
        }

        ul {
            padding-left: 2rem;
        }

        li {
            margin-bottom: 0.5rem;
        }

        /* Style for the contact section */
        #contact {
            background-color: #fff;
            padding: 2rem;
            border-radius: 5px;
            box-shadow: 0 2px 5px rgba(0,0,0,0.1);
            margin-top: 2rem;
        }

        /* Style for the skills section */
        .skills {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(250px, 1fr));
            gap: 1rem;
            margin-top: 1rem;
        }

        .skill-category {
            background-color: #fff;
            padding: 1rem;
            border-radius: 5px;
            box-shadow: 0 2px 5px rgba(0,0,0,0.1);
        }

        /* Style for papers list */
        .papers-list li {
            margin-bottom: 1rem;
            padding-left: 1rem;
            border-left: 3px solid #2c3e50;
        }

        em {
            color: #666;
            font-style: normal;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1 style="color: #2c3e50">Teun van der Weij</h1>
<h4 style="color: #666; margin-top: -10px; text-align: center">Resident @ Mantic</h4>
<h4 style="color: #666; margin-top: -10px; text-align: center">Co-founder & Board Member @ ENAIS</h4>

<h2>Table of Contents</h2>
<ul>
<li><a href="#about-me">About Me</a></li>
<li><a href="#work-experience">Work Experience</a></li>
<li><a href="#education">Education</a></li>
<li><a href="#recent-activity-highlights">Recent Activity Highlights</a></li>
<li><a href="#research-papers">Research Papers</a></li>
<li><a href="#contact">Contact</a></li>
</ul>
<div style="overflow: hidden; margin-top: -200px;">
<img src="weij002_cropped.jpg" alt="teun van der weij" width="200" height="200" style="float: right; margin-left: 20px; margin-bottom: 10px;">

<p>&nbsp;</p>

</div>

<h2 style="color: #34495e">About Me</h2>
<p>I am an AI safety researcher currently working as a MATS Scholar, focusing on strategic underperformance on evaluations (sandbagging) of general purpose AI. I'm also a co-founder and board member of ENAIS (European Network for AI Safety), working to improve coordination between AI Safety researchers and policymakers in Europe.</p>
<h2 style="color: #34495e">Work Experience</h2>
<h3 style="color: #3498db">Resident</h3>
<p><strong>August 2024 – Present | Mantic | London, UK</strong></p>
<p>A research scientist role with the goal of creating an AI superforecaster.</p>
<h3 style="color: #3498db">Research Scholar</h3>
<p><strong>Jan 2024 – Jul 2024 | MATS | Berkeley, CA, US, and London, UK</strong></p>
<p>Working on strategic underperformance on evaluations (sandbagging) of general purpose AI under the mentorship of Francis Rhys Ward.</p>
<h3 style="color: #3498db">Co-founder and Co-director</h3>
<p><strong>Dec 2022 – Present | ENAIS | Remote</strong></p>
<p>Leading initiatives to improve coordination and collaboration between AI Safety researchers and policymakers in Europe.</p>
<h3 style="color: #3498db">Junior Researcher</h3>
<p><strong>Feb 2022 – May 2022 | UC Berkeley | Remote</strong></p>
<p>Participated in the Supervised Program for Alignment Research, focusing on evaluating the shutdown problem in language models.</p>
<h2 style="color: #34495e">Education</h2>
<h3 style="color: #3498db">MSc Student</h3>
<p><strong>Sep 2022 – Nov 2024 | Utrecht University | Netherlands</strong></p>
<p>Coursework includes Advanced Machine Learning, Natural Language Processing, Human-centered Machine Learning, Pattern Recognition &amp; Deep Learning, and Philosophy of AI.</p>
<p>Grade: 8.2/10</p>
<h3 style="color: #3498db">BSc Student</h3>
<p><strong>2018 – 2021 | University College Groningen | Netherlands</strong></p>
<p>Focus on AI, philosophy, and psychology.</p>
<p>Graduated summa cum laude (with highest distinction).</p>
<h3 style="color: #3498db">High School Student</h3>
<h2 style="color: #34495e">Recent Activity Highlights</h2>
<h3 style="color: #3498db">Resident</h3>
<p><strong>October 2024 | Mantic | London, UK</strong>
- Announced a new role at <strong>Mantic</strong>, an AI-powered forecasting startup. Researching predictive systems for future events, such as pandemics, elections, and AI developments.
- Highlighted a positive response to the paper <em>AI Sandbagging: Language Models can Strategically Underperform on Evaluations</em> and shared follow-up research in collaboration with organizations like Anthropic and GovAI.</p>
<h3 style="color: #3498db">Research Scholar</h3>
<p><strong>June 2024 | MATS | Berkeley, CA</strong>
- Released a paper on sandbagging, exploring the risks posed by AI systems that can hide capabilities during evaluations. The work emphasizes the importance of trustworthy AI evaluations.</p>
<h3 style="color: #3498db">Research Scholar</h3>
<p><strong>March 2024 | MATS | Berkeley, CA</strong>
- Shared findings from a study using activation steering to adjust language models' behaviors, addressing issues like myopia and wealth-seeking tendencies. </p>
<h3 style="color: #3498db">Research Scholar</h3>
<p><strong>January 2024 | MATS | Berkeley, CA</strong>
- Moderated a high-profile Q&amp;A event with OpenAI and Alignment Research Center researchers, attracting over 1,800 attendees to discuss existential risks posed by AI.</p>
<h2 style="color: #34495e">Research Papers</h2>
<p><a href="https://scholar.google.com/citations?hl=en&amp;view_op=list_works&amp;gmla=ALUCkoWPBCLgqYHwqX7Iw_wQzACyuhxQEz49m-BCVVztAA1-XCw5_Zhsk6n5KCnQLWmbYawMlu5orNjSmAXfq_8Q-_HV&amp;user=-fMmbSYAAAAJ">Google Scholar</a></p>
<ul>
<li><strong>van der Weij, T., Hofstätter, F., Jaffe, O., Brown, S. F., &amp; Ward, F. R.</strong> (2024). <em>AI Sandbagging: Language Models can Strategically Underperform on Evaluations.</em> <a href="https://arxiv.org/abs/2406.07358">arXiv preprint arXiv:2406.07358</a>.</li>
<li><strong>van der Weij, T., Poesio, M., &amp; Schoots, N.</strong> (2024). <em>Extending Activation Steering to Broad Skills and Multiple Behaviours.</em> <a href="https://arxiv.org/abs/2403.05767">arXiv preprint arXiv:2403.05767</a>.</li>
<li><strong>van der Weij, T., &amp; Lermen, S.</strong> (2023). <em>Evaluating Shutdown Avoidance of Language Models in Textual Scenarios.</em> <a href="https://arxiv.org/abs/2307.00787">arXiv preprint arXiv:2307.00787</a>.</li>
<li><strong>van der Weij, T., Soancatl Aguilar, V., &amp; Solorio-Fernández, S.</strong> (2022). <em>Runtime Prediction of Filter Unsupervised Feature Selection Methods.</em> <a href="https://www.rcs.cic.ipn.mx/2022_150_8/Runtime%20Prediction%20of%20Filter%20Unsupervised%20Feature%20Selection%20Methods.pdf">Research in Computing Science, 150(8), 138-150</a>.</li>
</ul>
<h2 style="color: #34495e">Contact</h2>
<p><strong>Email:</strong> mailvanteun@gmail.com</p>
    </div>
</body>
</html>